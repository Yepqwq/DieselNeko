var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
var __export = (target, all) => {
  for (var name2 in all)
    __defProp(target, name2, { get: all[name2], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  Config: () => Config,
  apply: () => apply,
  name: () => name
});
module.exports = __toCommonJS(src_exports);
var import_koishi = require("koishi");
var import_plugin_console = require("@koishijs/plugin-console");
var import_path = require("path");
var import_promises2 = require("fs/promises");

// src/file.ts
var import_promises = require("fs/promises");
var import_buffer = require("buffer");
var FileWriter = class {
  constructor(date, path) {
    this.date = date;
    this.path = path;
    this.task = (0, import_promises.open)(path, "a+").then(async (handle) => {
      const buffer = await handle.readFile();
      this.data = this.parse(new TextDecoder().decode(buffer));
      this.size = buffer.byteLength;
      return handle;
    });
    this.task.then(() => this.flush());
  }
  static {
    __name(this, "FileWriter");
  }
  data;
  task;
  size;
  temp = [];
  flush() {
    if (!this.temp.length)
      return;
    this.task = this.task.then(async (handle) => {
      const content = import_buffer.Buffer.from(this.temp.map((record) => JSON.stringify(record) + "\n").join(""));
      await handle.write(content);
      this.data.push(...this.temp);
      this.size += content.byteLength;
      this.temp = [];
      return handle;
    });
  }
  parse(text) {
    return text.split("\n").map((line) => {
      try {
        return JSON.parse(line);
      } catch {
      }
    }).filter(Boolean);
  }
  async read() {
    await this.task;
    return this.data;
  }
  write(record) {
    this.temp.push(record);
    this.flush();
  }
  async close() {
    const handle = await this.task;
    await handle.close();
  }
};

// src/locales/zh-CN.yml
var zh_CN_default = { root: "存放输出日志的本地目录。", maxAge: "日志文件保存的最大天数。", maxSize: "单个日志文件的最大大小。" };

// src/index.ts
var import_meta = {};
var name = "logger";
var LogProvider = class extends import_plugin_console.DataService {
  constructor(ctx, getWriter) {
    super(ctx, "logs", { authority: 4 });
    this.getWriter = getWriter;
    ctx.console.addEntry(process.env.KOISHI_BASE ? [
      process.env.KOISHI_BASE + "/dist/index.js",
      process.env.KOISHI_BASE + "/dist/style.css"
    ] : process.env.KOISHI_ENV === "browser" ? [
      // @ts-ignore
      import_meta.url.replace(/\/src\/[^/]+$/, "/client/index.ts")
    ] : {
      dev: (0, import_path.resolve)(__dirname, "../client/index.ts"),
      prod: (0, import_path.resolve)(__dirname, "../dist")
    });
  }
  static {
    __name(this, "LogProvider");
  }
  async get() {
    return this.getWriter()?.read();
  }
};
var Config = import_koishi.Schema.object({
  root: import_koishi.Schema.path({
    filters: ["directory"],
    allowCreate: true
  }).default("data/logs"),
  maxAge: import_koishi.Schema.natural().default(30),
  maxSize: import_koishi.Schema.natural().default(1024 * 100)
}).i18n({
  "zh-CN": zh_CN_default
});
async function apply(ctx, config) {
  const root = (0, import_path.resolve)(ctx.baseDir, config.root);
  await (0, import_promises2.mkdir)(root, { recursive: true });
  const files = {};
  for (const filename of await (0, import_promises2.readdir)(root)) {
    const capture = /^(\d{4}-\d{2}-\d{2})-(\d+)\.log$/.exec(filename);
    if (!capture)
      continue;
    files[capture[1]] ??= [];
    files[capture[1]].push(+capture[2]);
  }
  let writer;
  async function createFile(date2, index) {
    writer = new FileWriter(date2, `${root}/${date2}-${index}.log`);
    const { maxAge } = config;
    if (!maxAge)
      return;
    const now = Date.now();
    for (const date3 of Object.keys(files)) {
      if (now - +new Date(date3) < maxAge * import_koishi.Time.day)
        continue;
      for (const index2 of files[date3]) {
        await (0, import_promises2.rm)(`${root}/${date3}-${index2}.log`).catch((error) => {
          ctx.logger("logger").warn(error);
        });
      }
      delete files[date3];
    }
  }
  __name(createFile, "createFile");
  const date = (/* @__PURE__ */ new Date()).toISOString().slice(0, 10);
  createFile(date, Math.max(...files[date] ?? [0]) + 1);
  let buffer = [];
  const update = ctx.throttle(() => {
    ctx.get("console")?.patch("logs", buffer);
    buffer = [];
  }, 100);
  const loader = ctx.get("loader");
  const target = {
    colors: 3,
    record: (record) => {
      record.meta ||= {};
      const scope = record.meta[import_koishi.Context.current]?.scope;
      if (loader && scope) {
        record.meta.paths = loader.paths(scope);
      }
      const date2 = new Date(record.timestamp).toISOString().slice(0, 10);
      if (writer.date !== date2) {
        writer.close();
        files[date2] = [1];
        createFile(date2, 1);
      }
      writer.write(record);
      buffer.push(record);
      update();
      if (writer.size >= config.maxSize) {
        writer.close();
        const index = Math.max(...files[date2] ?? [0]) + 1;
        files[date2] ??= [];
        files[date2].push(index);
        createFile(date2, index);
      }
    }
  };
  import_koishi.Logger.targets.push(target);
  ctx.on("dispose", () => {
    writer?.close();
    (0, import_koishi.remove)(import_koishi.Logger.targets, target);
    if (loader) {
      loader.prolog = [];
    }
  });
  for (const record of loader?.prolog || []) {
    target.record(record);
  }
  ctx.plugin(LogProvider, () => writer);
}
__name(apply, "apply");
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  Config,
  apply,
  name
});
//# sourceMappingURL=index.js.map
